select(QC_1_K)
QC_1_K_stats <- stat.desc(QC_1_K_col)
QC_1_K_stats[1:3,1:2]
QC_1_K_col <- qc_1_k_df %>%
select(QC_1_K)
QC_1_K_stats <- stat.desc(QC_1_K_col)
QC_1_K_stats[1:3,:]
QC_1_K_col <- qc_1_k_df %>%
select(QC_1_K)
QC_1_K_stats <- stat.desc(QC_1_K_col)
QC_1_K_stats[1:3,0:1]
QC_1_K_col <- qc_1_k_df %>%
select(QC_1_K)
QC_1_K_stats <- stat.desc(QC_1_K_col)
QC_1_K_stats['mean',0:1]
QC_1_K_col <- qc_1_k_df %>%
select(QC_1_K)
QC_1_K_stats <- stat.desc(QC_1_K_col)
QC_1_K_mean <- QC_1_K_stats['mean',0:1]
QC_1_K_sd <- QC_1_K_stats['standard deviation',0:1]
#mean(as.vector(QC_1_K_col),na.rm=TRUE)
QC_1_K_cv <- (QC_1_K_mean / QC_1_K_sd) * 100
QC_1_K_cv
#mean(as.vector(QC_1_K_col),na.rm=TRUE)
QC_1_K_cv <- (QC_1_K_mean / QC_1_K_sd) * 100
QC_1_K_sd
QC_1_K_col <- qc_1_k_df %>%
select(QC_1_K)
QC_1_K_stats <- stat.desc(QC_1_K_col)
QC_1_K_mean <- QC_1_K_stats['mean',0:1]
QC_1_K_sd <- QC_1_K_stats['std.dev',0:1]
#mean(as.vector(QC_1_K_col),na.rm=TRUE)
QC_1_K_cv <- (QC_1_K_mean / QC_1_K_sd) * 100
QC_1_K_sd
#mean(as.vector(QC_1_K_col),na.rm=TRUE)
QC_1_K_cv <- (QC_1_K_mean / QC_1_K_sd) * 100
QC_1_K_cv
qc_1_k_df <- read_csv('qc_1_k.csv')
head(qc_1_k_df)
XmR_Plot <-
ggplot(qc_1_k_df, aes(x = Run_Number, y = QC_1_K)) + #init ggplot
geom_point() + geom_line() + # add the points and lines
stat_QC(method = "XmR",      # specify QC charting method
auto.label = T,      # Use Autolabels
label.digits = 2,    # Use two digit in the label
show.1n2.sigma = T   # Show 1 and two sigma lines
) +
scale_x_continuous(expand =  expand_scale(mult = .15))  # Pad the x-axis
XmR_Plot
QC_1_K_col <- qc_1_k_df %>%
select(QC_1_K)
QC_1_K_stats <- stat.desc(QC_1_K_col)
QC_1_K_mean <- QC_1_K_stats['mean',0:1]
QC_1_K_sd <- QC_1_K_stats['std.dev',0:1]
#mean(as.vector(QC_1_K_col),na.rm=TRUE)
QC_1_K_cv <- (QC_1_K_mean / QC_1_K_sd) * 100
QC_1_K_cv
QC_1_K_stats
qc_1_k_csv = path + 'qc_1_k.csv'
#mean(as.vector(QC_1_K_col),na.rm=TRUE)
QC_1_K_cv <- (QC_1_K_mean / QC_1_K_sd) * 100
QC_1_K_cv
#mean(as.vector(QC_1_K_col),na.rm=TRUE)
QC_1_K_cv <- (QC_1_K_sd / QC_1_K_mean) * 100
QC_1_K_cv
QC_1_K_col <- qc_1_k_df %>%
select(QC_1_K)
QC_1_K_stats <- stat.desc(QC_1_K_col)
QC_1_K_mean <- QC_1_K_stats['mean',0:1]
QC_1_K_sd <- QC_1_K_stats['std.dev',0:1]
#mean(as.vector(QC_1_K_col),na.rm=TRUE)
QC_1_K_cv <- (QC_1_K_sd / QC_1_K_mean) * 100
QC_1_K_cv
install.packages('caret')
library(caret)
library(caret)
install.packages('caret')
library(caret)
install.packages('caret')
library(caret)
#Creates vectors having data points
expected_value <- factor(c(1,0,1,0,1,1,1,0,0,1))
predicted_value <- factor(c(1,0,0,1,1,1,0,0,0,1))
#Creating confusion matrix
example <- confusionMatrix(data=predicted_value, reference = expected_value)
install.packages("caret",
repos = "http://cran.r-project.org",
dependencies = c("Depends", "Imports", "Suggests"))
library(caret)
install.packages("caret")
install.packages("cvms", repos = "https://cloud.r-project.org")
install.packages("caret", repos = "https://cloud.r-project.org")
install.packages("ConfusionTableR", repos = "https://cloud.r-project.org")
install.packages("tidyverse")
install.packages("ggQC")
install.packages("caret", repos = "https://cloud.r-project.org")
library(caret)
#Creates vectors having data points
expected_value <- factor(c(1,0,1,0,1,1,1,0,0,1))
predicted_value <- factor(c(1,0,0,1,1,1,0,0,0,1))
#Creating confusion matrix
example <- confusionMatrix(data=predicted_value, reference = expected_value)
#Display results
example
install.packages("mcr", repos = "https://cloud.r-project.org")
library(tidyverse)
library(ggQC)
library(caret)
library(mcr)
set.seed(20)
x <- runif(100,0,100)
y <- 1.10*x - 0.001*x^2 + rnorm(100,0,1)*(2 + 0.05*x) + 15
dem.reg <- mcreg(x,y, method.reg = "Deming")
set.seed(20)
x <- runif(100,0,100)
y <- 1.10*x - 0.001*x^2 + rnorm(100,0,1)*(2 + 0.05*x) + 15
dem.reg <- mcreg(x,y, method.reg = "Deming")
dem.reg
set.seed(20)
x <- runif(100,0,100)
y <- 1.10*x - 0.001*x^2 + rnorm(100,0,1)*(2 + 0.05*x) + 15
dem.reg <- mcreg(x,y, method.reg = "Deming")
str(dem.reg)
set.seed(20)
x <- runif(100,0,100)
y <- 1.10*x - 0.001*x^2 + rnorm(100,0,1)*(2 + 0.05*x) + 15
dem.reg <- mcreg(x,y, method.reg = "Deming")
str(dem.reg)
dem.reg@para
plot(x,y, main = "Regression Comparison", xlab = "Current Method", ylab = "New Method")
abline(dem.reg@para[1:2], col = "blue")
plot(x,y, main = "Regression Comparison", xlab = "Current Method", ylab = "New Method")
abline(dem.reg@para[1:2], col = "blue")
legend("topleft",legend=paste("R2 is", format(summary(Model)$r.squared,digits=3)))
plot(x,y, main = "Regression Comparison", xlab = "Current Method", ylab = "New Method")
abline(dem.reg@para[1:2], col = "blue")
legend("topleft",legend=paste("R2 is", dem.reg$r.squared,digits=3)))
plot(x,y, main = "Regression Comparison", xlab = "Current Method", ylab = "New Method")
abline(dem.reg@para[1:2], col = "blue")
legend("topleft",legend=paste("R2 is", dem.reg,digits=3)))
plot(x,y, main = "Regression Comparison", xlab = "Current Method", ylab = "New Method")
abline(dem.reg@para[1:2], col = "blue")
legend("topleft",legend=paste("R2 is", dem.reg@para,digits=3)))
MCResult.plotResiduals(
dem.reg,
res.type = c("optimized", "y", "x"),
xaxis = c("yhat", "both", "xhat"),
ref.line = TRUE,
ref.line.col = "red",
ref.line.lty = 2,
ref.line.lwd = 1,
main = NULL,
xlab = NULL,
ylab = NULL,
add.grid = TRUE,
...
)
MCResult.plotResiduals(
dem.reg
)
rm(list = ls())
#Setting the working directory
setwd("D:/Edwisor_Project - Loan_Defaulter/")
install.packages("verification")
library(verification)
data<-data.frame(expected_value,predicted_value)
data<-data.frame(expected_value,predicted_value)
#Creates vectors having data points
expected_value <- factor(c(1,0,1,0,1,1,1,0,0,1))
predicted_value <- factor(c(1,0,0,1,1,1,0,0,0,1))
#Creating confusion matrix
example <- confusionMatrix(data=predicted_value, reference = expected_value)
#Display results
example
data<-data.frame(expected_value,predicted_value)
#names(data)<-c("yes","no")
roc.plot(data$expected_value, data$predicted_value)
data<-data.frame(expected_value,predicted_value)
#names(data)<-c("yes","no")
roc.plot(data$expected_value, data$predicted_value)
data<-data.frame(expected_value,predicted_value)
data
#names(data)<-c("yes","no")
#roc.plot(data$expected_value, data$predicted_value)
TN =CM[1,1]
err_metric=function(CM)
{
TN =CM[1,1]
TP =CM[2,2]
FP =CM[1,2]
FN =CM[2,1]
precision =(TP)/(TP+FP)
recall_score =(FP)/(FP+TN)
f1_score=2*((precision*recall_score)/(precision+recall_score))
accuracy_model  =(TP+TN)/(TP+TN+FP+FN)
False_positive_rate =(FP)/(FP+TN)
False_negative_rate =(FN)/(FN+TP)
print(paste("Precision value of the model: ",round(precision,2)))
print(paste("Accuracy of the model: ",round(accuracy_model,2)))
print(paste("Recall value of the model: ",round(recall_score,2)))
print(paste("False Positive rate of the model: ",round(False_positive_rate,2)))
print(paste("False Negative rate of the model: ",round(False_negative_rate,2)))
print(paste("f1 score of the model: ",round(f1_score,2)))
}
err_metric=function(CM)
{
TN =CM[1,1]
TP =CM[2,2]
FP =CM[1,2]
FN =CM[2,1]
precision =(TP)/(TP+FP)
recall_score =(FP)/(FP+TN)
f1_score=2*((precision*recall_score)/(precision+recall_score))
accuracy_model  =(TP+TN)/(TP+TN+FP+FN)
False_positive_rate =(FP)/(FP+TN)
False_negative_rate =(FN)/(FN+TP)
print(paste("Precision value of the model: ",round(precision,2)))
print(paste("Accuracy of the model: ",round(accuracy_model,2)))
print(paste("Recall value of the model: ",round(recall_score,2)))
print(paste("False Positive rate of the model: ",round(False_positive_rate,2)))
print(paste("False Negative rate of the model: ",round(False_negative_rate,2)))
print(paste("f1 score of the model: ",round(f1_score,2)))
}
print(error_metric)
err_metric=function(CM)
{
TN =CM[1,1]
TP =CM[2,2]
FP =CM[1,2]
FN =CM[2,1]
precision =(TP)/(TP+FP)
recall_score =(FP)/(FP+TN)
f1_score=2*((precision*recall_score)/(precision+recall_score))
accuracy_model  =(TP+TN)/(TP+TN+FP+FN)
False_positive_rate =(FP)/(FP+TN)
False_negative_rate =(FN)/(FN+TP)
print(paste("Precision value of the model: ",round(precision,2)))
print(paste("Accuracy of the model: ",round(accuracy_model,2)))
print(paste("Recall value of the model: ",round(recall_score,2)))
print(paste("False Positive rate of the model: ",round(False_positive_rate,2)))
print(paste("False Negative rate of the model: ",round(False_negative_rate,2)))
print(paste("f1 score of the model: ",round(f1_score,2)))
}
print(error_metric(cm))
install.packages("pROC")
install.packages("pROC")
library(pROC)
install.packages("pROC")
install.packages("randomForest")
install.packages("pROC")
library(pROC)
library(randomForest)
set.seed(420)
num.samples <= 100
set.seed(420)
num.samples <- 100
weight <- sort(rnorm(n=num.samples, mean=127, sd=29))
set.seed(420)
num.samples <- 100
weight <- sort(rnorm(n=num.samples, mean=127, sd=29))
head(weight)
obese <- ifelse(test=(runif(n=num.samples)) < (rank(weight/100)), yes=1, no=0 )
obese
obese <- ifelse(test=(runif(n=num.samples)) < (rank(weight/100)), yes=1, no=0 )
obese <- ifelse(test=(runif(n=num.samples)) < (rank(weight/100)), yes=1, no=0 )
obese
obese <- ifelse(test=(runif(n=num.samples) < (rank(weight)/100)), yes=1, no=0 )
obese
set.seed(420)
num.samples <- 100
weight <- sort(rnorm(n=num.samples, mean=127, sd=29))
head(weight)
set.seed(420)
num.samples <- 100
weight <- sort(rnorm(n=num.samples, mean=127, sd=29))
weight
plot(x=weight, y=obese)
glm.fit = glm(obese~ weight, family=binomial)
lines(weight, glm.fit$fitted.values)
glm.fit = glm(obese ~ weight, family=binomial)
lines(weight, glm.fit$fitted.values)
glm.fit = glm(obese ~ weight, family=binomial)
#lines(weight, glm.fit$fitted.values)
glm.fit = glm(obese ~ weight, family=binomial)
glm.fi
glm.fit = glm(obese ~ weight, family=binomial)
glm.fit
#lines(weight, glm.fit$fitted.values)
lines(weight, glm.fit$fitted.values)
plot(x=weight, y=obese)
lines(weight, glm.fit$fitted.values)
pROC(obese, glm.fitted$fitted.values, plot=TRUE)
ROC(obese, glm.fitted$fitted.values, plot=TRUE)
roc(obese, glm.fitted$fitted.values, plot=TRUE)
roc(obese, glm.fit$fitted.values, plot=TRUE)
roc(obese, glm.fit$fitted.values, plot=TRUE)
par(pty = "s")
# need to get rid of padding bug
par(pty = "s")
roc(obese, glm.fit$fitted.values, plot=TRUE)
# need to get rid of padding bug
par(pty = "s")
# legacy.axes=TRUE allows for 1 - Specificity in X axis
roc(obese, glm.fit$fitted.values, plot=TRUE, legacy.axes=TRUE)
# need to get rid of padding bug
par(pty = "s")
# legacy.axes=TRUE allows for 1 - Specificity in X axis
roc(obese, glm.fit$fitted.values, plot=TRUE, legacy.axes=TRU, lwd=4, col="#377eb8")
# need to get rid of padding bug
par(pty = "s")
# legacy.axes=TRUE allows for 1 - Specificity in X axis
roc(obese, glm.fit$fitted.values, plot=TRUE, legacy.axes=TRUE, lwd=4, col="#377eb8")
roc.df <- data.frame(
tpp=roc.info$sensitivies*100,
fpp=(1 = -roc.info$specificies)*100,
thresholds=roc.info$thresholds)
# need to get rid of padding bug
par(pty = "s")
# legacy.axes=TRUE allows for 1 - Specificity in X axis
# add parameter ' percent=TRUE ' to get TPR vs FPR in lieu of Sensitivity and Specificity
roc_info <- roc(obese, glm.fit$fitted.values, plot=TRUE, legacy.axes=TRUE, lwd=4, col="#377eb8")
roc_info
roc.df <- data.frame(
tpp=roc.info$sensitivies*100,
fpp=(1 = -roc.info$specificies)*100,
thresholds=roc.info$thresholds)
# need to get rid of padding bug
par(pty = "s")
# legacy.axes=TRUE allows for 1 - Specificity in X axis
# add parameter ' percent=TRUE ' to get TPR vs FPR in lieu of Sensitivity and Specificity
roc.info <- roc(obese, glm.fit$fitted.values, plot=TRUE, legacy.axes=TRUE, lwd=4, col="#377eb8")
roc.info
roc.df <- data.frame(
tpp=roc.info$sensitivies*100,
fpp=(1 = -roc.info$specificies)*100,
thresholds=roc.info$thresholds)
roc.df <- data.frame(
tpp=roc.info$sensitivities*100,
fpp=(1 = -roc.info$specificies)*100,
thresholds=roc.info$thresholds)
roc.df <- data.frame(
tpp=roc.info$sensitivities*100,
fpp=(1 = -roc.info$specificities)*100,
thresholds=roc.info$thresholds)
roc.df <- data.frame(
tpp=roc.info$sensitivities*100,
fpp=(1-roc.info$specificities)*100,
thresholds=roc.info$thresholds)
head(roc.df)
# need to get rid of padding bug
par(pty = "s")
# legacy.axes=TRUE allows for 1 - Specificity in X axis
# add parameter ' percent=TRUE ' to get TPR vs FPR in lieu of Sensitivity and Specificity
roc.info <- roc(obese, glm.fit$fitted.values, plot=TRUE,
legacy.axes=TRUE, lwd=4, col="#377eb8", print.auc.x=45)
roc.info
# need to get rid of padding bug
par(pty = "s")
# legacy.axes=TRUE allows for 1 - Specificity in X axis
# add parameter ' percent=TRUE ' to get TPR vs FPR in lieu of Sensitivity and Specificity
roc.info <- roc(obese, glm.fit$fitted.values, plot=TRUE,
legacy.axes=TRUE, lwd=4, col="#377eb8",
# printing the auc within the ROC
print.auc.x=45, partial.auc=c(100,90), auc.polygon = TRUE, auc.polygon= "#377eb822")
# need to get rid of padding bug
par(pty = "s")
# legacy.axes=TRUE allows for 1 - Specificity in X axis
# add parameter ' percent=TRUE ' to get TPR vs FPR in lieu of Sensitivity and Specificity
roc.info <- roc(obese, glm.fit$fitted.values, plot=TRUE,
legacy.axes=TRUE, lwd=4, col="#377eb8",
print.auc.x=45, partial.auc=c(100,90), auc.polygon = TRUE, auc.polygon= "#377eb822")
# need to get rid of padding bug
par(pty = "s")
# legacy.axes=TRUE allows for 1 - Specificity in X axis
# add parameter ' percent=TRUE ' to get TPR vs FPR in lieu of Sensitivity and Specificity
roc.info <- roc(obese, glm.fit$fitted.values, plot=TRUE,
legacy.axes=TRUE, lwd=4, col="#377eb8",
print.auc.x=45, partial.auc = c(100,90), auc.polygon = TRUE, auc.polygon.col = "#377eb822")
roc.info
mtcars_aov <- aov(mtcars$disp~factor(mtcars$gear))
summary(mtcars_aov)
# Variance in mean within group and between group
histogram(mtcars$disp~mtcars$gear, subset = (mtcars$am == 0),
xlab = "gear", ylab = "disp", main = "Automatic")
histogram(mtcars$disp~mtcars$gear, subset = (mtcars$am == 1),
xlab = "gear", ylab = "disp", main = "Manual")
# One-way ANOVA visualization
plot1 <- ggplot(mtcars, aes(x = factor(gear), y = disp, fill = factor(gear))) +
geom_boxplot(color = "black", alpha = 0.7) +
labs(title = "One-Way ANOVA",
x = "Gear",
y = "Displacement") +
theme_minimal() +
theme(legend.position = "top")
# Two-way ANOVA visualization
plot2 <- ggplot(mtcars, aes(x = factor(gear), y = disp, fill = factor(am))) +
geom_boxplot(color = "black", alpha = 0.7) +
labs(title = "Two-Way ANOVA",
x = "Gear",
y = "Displacement") +
theme_minimal() +
theme(legend.position = "top")
# Combine the plots for comparison
library(gridExtra)
install.packages("gridExtra")
library(gridExtra)
# One-way ANOVA visualization
plot1 <- ggplot(mtcars, aes(x = factor(gear), y = disp, fill = factor(gear))) +
geom_boxplot(color = "black", alpha = 0.7) +
labs(title = "One-Way ANOVA",
x = "Gear",
y = "Displacement") +
theme_minimal() +
theme(legend.position = "top")
# Two-way ANOVA visualization
plot2 <- ggplot(mtcars, aes(x = factor(gear), y = disp, fill = factor(am))) +
geom_boxplot(color = "black", alpha = 0.7) +
labs(title = "Two-Way ANOVA",
x = "Gear",
y = "Displacement") +
theme_minimal() +
theme(legend.position = "top")
# Combine the plots for comparison
library(gridExtra)
grid.arrange(plot1, plot2, ncol = 2)
install.packages("tidyverse")
install.packages("ggQC")
install.packages("tidyverse")
library(tidyverse)
library(ggQC)
library(caret)
library(mcr)
library(verification)
library(pROC)
library(gridExtra)
library(pastecs)
library(forecast)
library(TTR)
library(ggpubr)
install.packages("ggpubr")
library(tidyverse)
library(ggQC)
library(caret)
library(mcr)
library(verification)
library(pROC)
library(gridExtra)
library(pastecs)
library(forecast)
library(TTR)
library(ggpubr)
path = 'D:/Projects/Clinical Laboratory Statistics with R/'
setwd(path)
qc_1_k_df <- read_csv('qc_1_k.csv')
qc_1_k_df$QC_1_K <- rnorm(90,mean=2.5, sd=.1)
head(qc_1_k_df)
XmR_Plot <-
ggplot(qc_1_k_df, aes(x = Run_Number, y = QC_1_K)) + #init ggplot
geom_point() + geom_line() + # add the points and lines
labs(y = "Potassium L1 (md/dl)") +
stat_QC(method = "XmR" ,      # specify QC charting method
auto.label = T,      # Use Autolabels
label.digits = 2,    # Use two digit in the label
show.1n2.sigma = T   # Show 1 and two sigma lines
) +
scale_x_continuous(expand =  expand_scale(mult = .15))   # Pad the x-axis
XmR_Plot
# QC_1_K_col <- qc_1_k_df %>% select(QC_1_K)
QC_1_K_col <- qc_1_k_df$QC_1_K
QC_1_K_stats = data.frame(
QC_1_K_mean = mean(QC_1_K_col),
QC_1_K_sd = sd(QC_1_K_col),
QC_1_K_cv = ((sd(QC_1_K_col) / mean(QC_1_K_col)) * 100)
)
QC_1_K_stats
print("CV%: ")
QC_1_K_stats$QC_1_K_cv
hist(QC_1_K_col)
stat.desc(QC_1_K_col)
hist(log(QC_1_K_col))
print("Mean: ")
QC_1_K_mean
SMA(QC_1_K_col)[80:90]
((SMA(QC_1_K_col)[80:90] - QC_1_K_mean) / QC_1_K_mean ) * 100
print("Mean: ")
QC_1_K_stats$QC_1_K_mean
((SMA(QC_1_K_col)[80:90] - QC_1_K_stats$QC_1_K_mean) / QC_1_K_stats$QC_1_K_mean ) * 100
print("The slope of the linear regression model:")
model$coefficients[2]
model = lm(QC_1_K~Run_Number,qc_1_k_df)
model
print("The slope of the linear regression model:")
model$coefficients[2]
ggplot(qc_1_k_df, aes(x=Run_Number, y=QC_1_K)) +
geom_point() +
stat_smooth(method="lm", se=TRUE)
#stat_regline_equation(label.x.npc="center")
x=rnorm(90,mean=2.45,sd=0.07)
y=rnorm(90,mean=2.50,sd=0.10)
t.test(x, y, alternative = "two.sided", var.equal = FALSE)
Group_K_Mean = 2.4
Group_K_SD = 0.1
Group_K_CV = (Group_K_SD / Group_K_Mean) * 100
cat("Group Mean:",Group_K_Mean,"Group SD:",Group_K_SD,"Group CV:",Group_K_CV)
CVR = QC_1_K_cv / Group_K_CV
CVR = QC_1_K_stats$QC_1_K_cv / Group_K_CV
CVR
SDI = (QC_1_K_stats$QC_1_K_mean - Group_K_Mean) / Group_K_SD
SDI
sqrt((SDI**2) + CVR**2)
TAE = sqrt((SDI**2) + CVR**2)
TAE
